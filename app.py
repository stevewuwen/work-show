"""
èŒä½æ•°æ®åˆ†æä»ªè¡¨æ¿
åŸºäº Streamlit + Plotly + WordCloud æ„å»º
"""

import sqlite3
import json
from collections import Counter

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ============================================================
# é¡µé¢é…ç½®
# ============================================================
st.set_page_config(
    page_title="èŒä½æ•°æ®åˆ†æä»ªè¡¨æ¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("ğŸ“Š èŒä½æ•°æ®åˆ†æä»ªè¡¨æ¿")
st.markdown("---")

# ============================================================
# ä¸­å›½ä¸»è¦åŸå¸‚ç»çº¬åº¦æ˜ å°„ï¼ˆç”¨äºåœ°å›¾å¯è§†åŒ–ï¼‰
# ============================================================
CITY_COORDINATES = {
    "åŒ—äº¬": (39.9042, 116.4074),
    "ä¸Šæµ·": (31.2304, 121.4737),
    "å¹¿å·": (23.1291, 113.2644),
    "æ·±åœ³": (22.5431, 114.0579),
    "æˆéƒ½": (30.5728, 104.0668),
    "æ­¦æ±‰": (30.5928, 114.3055),
    "è¥¿å®‰": (34.3416, 108.9398),
    "æ­å·": (30.2741, 120.1551),
    "é‡åº†": (29.5630, 106.5516),
    "å—äº¬": (32.0603, 118.7969),
    "å¤©æ´¥": (39.3434, 117.3616),
    "è‹å·": (31.2990, 120.5853),
    "éƒ‘å·": (34.7466, 113.6254),
    "é•¿æ²™": (28.2282, 112.9388),
    "ä¸œè": (23.0430, 113.7633),
    "æ²ˆé˜³": (41.8057, 123.4315),
    "é’å²›": (36.0671, 120.3826),
    "åˆè‚¥": (31.8206, 117.2272),
    "ä½›å±±": (23.0218, 113.1219),
    "å®æ³¢": (29.8683, 121.5440),
    "æ˜†æ˜": (25.0389, 102.7183),
    "å¤§è¿": (38.9140, 121.6147),
    "ç¦å·": (26.0745, 119.2965),
    "å¦é—¨": (24.4798, 118.0894),
    "å“ˆå°”æ»¨": (45.8038, 126.5350),
    "æµå—": (36.6512, 117.1201),
    "æ¸©å·": (28.0006, 120.6721),
    "å—å®": (22.8170, 108.3665),
    "é•¿æ˜¥": (43.8171, 125.3235),
    "æ³‰å·": (24.8741, 118.6757),
    "çŸ³å®¶åº„": (38.0428, 114.5149),
    "è´µé˜³": (26.6470, 106.6302),
    "å—æ˜Œ": (28.6820, 115.8579),
    "é‡‘å": (29.0792, 119.6474),
    "å¸¸å·": (31.8106, 119.9740),
    "æƒ å·": (23.1116, 114.4158),
    "å˜‰å…´": (30.7522, 120.7550),
    "å¤ªåŸ": (37.8706, 112.5489),
    "å¾å·": (34.2044, 117.2860),
    "å—é€š": (31.9807, 120.8940),
    "ç æµ·": (22.2710, 113.5767),
    "ä¸­å±±": (22.5176, 113.3926),
    "ä¿å®š": (38.8739, 115.4646),
    "å…°å·": (36.0611, 103.8343),
    "å°å·": (28.6563, 121.4205),
    "ç»å…´": (30.0306, 120.5800),
    "çƒŸå°": (37.4638, 121.4479),
    "å»ŠåŠ": (39.5186, 116.6831),
    "æ´›é˜³": (34.6197, 112.4540),
    "ä¹Œé²æœ¨é½": (43.8256, 87.6168),
    "æ— é”¡": (31.4912, 120.3119),
    "æµ·å£": (20.0440, 110.1999),
    "ä¸‰äºš": (18.2528, 109.5119),
    "æ‹‰è¨": (29.6500, 91.1000),
    "é“¶å·": (38.4872, 106.2309),
    "è¥¿å®": (36.6171, 101.7782),
    "å‘¼å’Œæµ©ç‰¹": (40.8424, 111.7490),
    "é¦™æ¸¯": (22.3193, 114.1694),
    "æ¾³é—¨": (22.1987, 113.5439),
    "å°åŒ—": (25.0330, 121.5654),
}


# ============================================================
# æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ï¼ˆå¸¦ç¼“å­˜ï¼‰
# ============================================================
@st.cache_data
def load_data():
    """
    ä» SQLite æ•°æ®åº“åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†
    ä½¿ç”¨ @st.cache_data ç¼“å­˜ï¼Œé¿å…é‡å¤æŸ¥è¯¢æ•°æ®åº“
    """
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect("job_info.sqlite")
    df = pd.read_sql_query("SELECT * FROM jobs", conn)
    conn.close()

    # JSON è§£æè¾…åŠ©å‡½æ•°
    def parse_json_list(value):
        """å®‰å…¨è§£æ JSON æ•°ç»„å­—ç¬¦ä¸²"""
        if pd.isna(value) or value == "" or value is None:
            return []
        try:
            result = json.loads(value)
            if isinstance(result, list):
                return result
            return []
        except (json.JSONDecodeError, TypeError):
            return []

    def clean_city_name(city):
        """æ¸…ç†åŸå¸‚åç§°ï¼Œå»é™¤'å¸‚'ã€'çœ'åç¼€"""
        if isinstance(city, str):
            return city.replace("å¸‚", "").replace("çœ", "")
        return city

    # è§£æ JSON å­—æ®µ
    df["city"] = df["city"].apply(parse_json_list)
    df["city"] = df["city"].apply(lambda cities: [clean_city_name(c) for c in cities])
    df["description_keywords"] = df["description_keywords"].apply(parse_json_list)
    df["requirement_keywords"] = df["requirement_keywords"].apply(parse_json_list)

    # æ—¶é—´è½¬æ¢
    df["publish_date"] = pd.to_datetime(df["publish_date"], unit="s", errors="coerce")
    df["crawl_date"] = pd.to_datetime(df["crawl_date"], unit="s", errors="coerce")

    # è®¡ç®—å¹³å‡è–ªèµ„ï¼ˆç”¨äºæœ‰è–ªèµ„æ•°æ®çš„è®°å½•ï¼‰
    df["salary_avg"] = df.apply(
        lambda row: (row["salary_min"] + row["salary_max"]) / 2
        if pd.notna(row["salary_min"]) and pd.notna(row["salary_max"])
        else np.nan,
        axis=1,
    )

    return df


# åŠ è½½æ•°æ®
df = load_data()

# ============================================================
# ä¾§è¾¹æ ç­›é€‰å™¨
# ============================================================
st.sidebar.header("ğŸ” æ•°æ®ç­›é€‰")

# æ¥æºå¹³å°ç­›é€‰
all_platforms = df["source_platform"].dropna().unique().tolist()
selected_platforms = st.sidebar.multiselect(
    "æ¥æºå¹³å°", options=all_platforms, default=[]
)

# åŸå¸‚ç­›é€‰ï¼ˆéœ€è¦å±•å¼€åˆ—è¡¨ï¼‰
all_cities = sorted(set(city for cities in df["city"] for city in cities if city))
selected_cities = st.sidebar.multiselect("åŸå¸‚", options=all_cities, default=[])

# å·¥ä½œç±»å‹ç­›é€‰
all_work_types = df["work_type"].dropna().unique().tolist()
selected_work_types = st.sidebar.multiselect(
    "å·¥ä½œç±»å‹", options=all_work_types, default=[]
)

# å·¥ä½œåˆ†ç±»ç­›é€‰
all_categories = df["category"].dropna().unique().tolist()
selected_categories = st.sidebar.multiselect(
    "å·¥ä½œåˆ†ç±»", options=all_categories, default=[]
)

# å­¦å†è¦æ±‚ç­›é€‰
all_education = df["education_req"].dropna().unique().tolist()
selected_education = st.sidebar.multiselect(
    "å­¦å†è¦æ±‚", options=all_education, default=[]
)

# ç»éªŒè¦æ±‚ç­›é€‰
all_experience = df["experience_req"].dropna().unique().tolist()
selected_experience = st.sidebar.multiselect(
    "ç»éªŒè¦æ±‚", options=all_experience, default=[]
)

# å‘å¸ƒæ—¥æœŸèŒƒå›´
min_date = df["publish_date"].min()
max_date = df["publish_date"].max()

if pd.notna(min_date) and pd.notna(max_date):
    date_range = st.sidebar.date_input(
        "å‘å¸ƒæ—¥æœŸèŒƒå›´",
        value=(min_date.date(), max_date.date()),
        min_value=min_date.date(),
        max_value=max_date.date(),
    )
else:
    date_range = None


# ============================================================
# æ•°æ®ç­›é€‰é€»è¾‘
# ============================================================
def filter_data(
    df, platforms, cities, work_types, categories, education, experience, date_range
):
    """æ ¹æ®ç­›é€‰æ¡ä»¶è¿‡æ»¤æ•°æ®"""
    filtered = df.copy()

    # æ¥æºå¹³å°
    if platforms:
        filtered = filtered[filtered["source_platform"].isin(platforms)]

    # åŸå¸‚ï¼ˆåªè¦èŒä½åŒ…å«é€‰å®šåŸå¸‚ä¹‹ä¸€å³å¯ï¼‰
    if cities:
        filtered = filtered[
            filtered["city"].apply(lambda x: any(c in cities for c in x))
        ]

    # å·¥ä½œç±»å‹
    if work_types:
        filtered = filtered[filtered["work_type"].isin(work_types)]

    # å·¥ä½œåˆ†ç±»
    if categories:
        filtered = filtered[filtered["category"].isin(categories)]

    # å­¦å†è¦æ±‚
    if education:
        filtered = filtered[filtered["education_req"].isin(education)]

    # ç»éªŒè¦æ±‚
    if experience:
        filtered = filtered[filtered["experience_req"].isin(experience)]

    # å‘å¸ƒæ—¥æœŸèŒƒå›´
    if date_range and len(date_range) == 2:
        start_date, end_date = date_range
        filtered = filtered[
            (filtered["publish_date"].dt.date >= start_date)
            & (filtered["publish_date"].dt.date <= end_date)
        ]

    return filtered


# åº”ç”¨ç­›é€‰
filtered_df = filter_data(
    df,
    selected_platforms,
    selected_cities,
    selected_work_types,
    selected_categories,
    selected_education,
    selected_experience,
    date_range,
)

# è–ªèµ„åˆ†ææ•°æ®ï¼ˆå‰”é™¤ç©ºå€¼ï¼‰
salary_df = filtered_df.dropna(subset=["salary_min", "salary_max"])

# ============================================================
# 1. å…³é”®æŒ‡æ ‡å¡ç‰‡
# ============================================================
st.subheader("ğŸ“ˆ å…³é”®æŒ‡æ ‡")

col1, col2, col3, col4, col5 = st.columns(5)

with col1:
    st.metric("èŒä½æ€»æ•°", f"{len(filtered_df):,}")

with col2:
    avg_salary = salary_df["salary_avg"].mean() if len(salary_df) > 0 else 0
    st.metric("å¹³å‡è–ªèµ„", f"Â¥{avg_salary:,.0f}")

with col3:
    company_count = filtered_df["company_name"].nunique()
    st.metric("å…¬å¸æ•°é‡", f"{company_count:,}")

with col4:
    median_salary = salary_df["salary_avg"].median() if len(salary_df) > 0 else 0
    st.metric("è–ªèµ„ä¸­ä½æ•°", f"Â¥{median_salary:,.0f}")

with col5:
    max_salary = salary_df["salary_max"].max() if len(salary_df) > 0 else 0
    st.metric("æœ€é«˜è–ªèµ„", f"Â¥{max_salary:,.0f}")

st.markdown("---")

# ============================================================
# ä½¿ç”¨ Tabs è¿›è¡Œå¸ƒå±€
# ============================================================
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
    [
        "ğŸ—ºï¸ åœ°ç†åˆ†å¸ƒ",
        "ğŸ“Š åˆ†ç±»åˆ†å¸ƒ",
        "ğŸ’° è–ªèµ„åˆ†æ",
        "ğŸ“… æ—¶é—´è¶‹åŠ¿",
        "â˜ï¸ å…³é”®è¯è¯äº‘",
        "ğŸ“‹ åŸå§‹æ•°æ®",
    ]
)

# ============================================================
# Tab 1: èŒä½åœ°ç†åˆ†å¸ƒ
# ============================================================
with tab1:
    st.subheader("ğŸ—ºï¸ èŒä½åœ°ç†åˆ†å¸ƒ (Top 20 åŸå¸‚)")

    # ç‚¸è£‚åŸå¸‚å­—æ®µç»Ÿè®¡
    city_exploded = filtered_df.explode("city")
    city_counts = city_exploded["city"].value_counts().head(20).reset_index()
    city_counts.columns = ["city", "count"]

    col1, col2 = st.columns(2)

    with col1:
        # æ°´å¹³æŸ±çŠ¶å›¾
        fig_bar = px.bar(
            city_counts.sort_values("count", ascending=True),
            x="count",
            y="city",
            orientation="h",
            title="Top 20 åŸå¸‚èŒä½æ•°é‡",
            labels={"count": "èŒä½æ•°é‡", "city": "åŸå¸‚"},
            color="count",
            color_continuous_scale="Blues",
        )
        fig_bar.update_layout(height=600, showlegend=False)
        st.plotly_chart(fig_bar, use_container_width=True)

    with col2:
        # åœ°å›¾å¯è§†åŒ–
        # æ·»åŠ ç»çº¬åº¦
        city_counts["lat"] = city_counts["city"].apply(
            lambda x: CITY_COORDINATES.get(x, (None, None))[0]
        )
        city_counts["lon"] = city_counts["city"].apply(
            lambda x: CITY_COORDINATES.get(x, (None, None))[1]
        )

        # è¿‡æ»¤æ‰æ²¡æœ‰åæ ‡çš„åŸå¸‚
        city_map_df = city_counts.dropna(subset=["lat", "lon"])

        if len(city_map_df) > 0:
            fig_map = px.scatter_mapbox(
                city_map_df,
                lat="lat",
                lon="lon",
                size="count",
                color="count",
                hover_name="city",
                hover_data={"count": True, "lat": False, "lon": False},
                title="èŒä½åœ°ç†åˆ†å¸ƒåœ°å›¾",
                color_continuous_scale="Viridis",
                size_max=50,
                zoom=3,
            )
            fig_map.update_layout(
                mapbox_style="open-street-map",
                height=600,
                margin={"r": 0, "t": 40, "l": 0, "b": 0},
            )
            st.plotly_chart(fig_map, use_container_width=True)
        else:
            st.warning("æ²¡æœ‰å¯ç”¨çš„åŸå¸‚åæ ‡æ•°æ®ç”¨äºåœ°å›¾æ˜¾ç¤º")

# ============================================================
# Tab 2: åˆ†ç±»åˆ†å¸ƒ
# ============================================================
with tab2:
    st.subheader("ğŸ“Š åˆ†ç±»åˆ†å¸ƒ")

    col1, col2, col3 = st.columns(3)

    with col1:
        # èŒä½åˆ†ç±»é¥¼å›¾
        category_counts = filtered_df["category"].value_counts().reset_index()
        category_counts.columns = ["category", "count"]

        fig_category = px.pie(
            category_counts.head(10),
            values="count",
            names="category",
            title="èŒä½åˆ†ç±»åˆ†å¸ƒ (Top 10)",
            hole=0.4,
        )
        fig_category.update_traces(textposition="inside", textinfo="percent+label")
        st.plotly_chart(fig_category, use_container_width=True)

    with col2:
        # å¹³å°åˆ†å¸ƒé¥¼å›¾
        platform_counts = filtered_df["source_platform"].value_counts().reset_index()
        platform_counts.columns = ["platform", "count"]

        fig_platform = px.pie(
            platform_counts,
            values="count",
            names="platform",
            title="æ¥æºå¹³å°åˆ†å¸ƒ",
            hole=0.4,
        )
        fig_platform.update_traces(textposition="inside", textinfo="percent+label")
        st.plotly_chart(fig_platform, use_container_width=True)

    with col3:
        # å·¥ä½œç±»å‹åˆ†å¸ƒé¥¼å›¾
        work_type_counts = filtered_df["work_type"].value_counts().reset_index()
        work_type_counts.columns = ["work_type", "count"]

        fig_work_type = px.pie(
            work_type_counts,
            values="count",
            names="work_type",
            title="å·¥ä½œç±»å‹åˆ†å¸ƒ",
            hole=0.4,
        )
        fig_work_type.update_traces(textposition="inside", textinfo="percent+label")
        st.plotly_chart(fig_work_type, use_container_width=True)

# ============================================================
# Tab 3: è–ªèµ„åˆ†æ
# ============================================================
with tab3:
    st.subheader("ğŸ’° è–ªèµ„åˆ†å¸ƒåˆ†æ")

    if len(salary_df) > 0:
        col1, col2 = st.columns(2)

        with col1:
            # è–ªèµ„åŒºé—´ç›´æ–¹å›¾
            fig_hist = px.histogram(
                salary_df,
                x="salary_avg",
                nbins=30,
                title="å¹³å‡è–ªèµ„åˆ†å¸ƒç›´æ–¹å›¾",
                labels={"salary_avg": "å¹³å‡è–ªèµ„ (å…ƒ)", "count": "èŒä½æ•°é‡"},
                color_discrete_sequence=["#636EFA"],
            )
            fig_hist.update_layout(
                xaxis_title="å¹³å‡è–ªèµ„ (å…ƒ)", yaxis_title="èŒä½æ•°é‡", bargap=0.1
            )
            st.plotly_chart(fig_hist, use_container_width=True)

        with col2:
            # å­¦å†å¯¹åº”è–ªèµ„ç®±çº¿å›¾
            fig_edu_box = px.box(
                salary_df,
                x="education_req",
                y="salary_avg",
                title="ä¸åŒå­¦å†è¦æ±‚çš„è–ªèµ„åˆ†å¸ƒ",
                labels={"education_req": "å­¦å†è¦æ±‚", "salary_avg": "å¹³å‡è–ªèµ„ (å…ƒ)"},
                color="education_req",
            )
            fig_edu_box.update_layout(showlegend=False)
            st.plotly_chart(fig_edu_box, use_container_width=True)

        # ç»éªŒå¯¹åº”è–ªèµ„ç®±çº¿å›¾
        fig_exp_box = px.box(
            salary_df,
            x="experience_req",
            y="salary_avg",
            title="ä¸åŒç»éªŒè¦æ±‚çš„è–ªèµ„åˆ†å¸ƒ",
            labels={"experience_req": "ç»éªŒè¦æ±‚", "salary_avg": "å¹³å‡è–ªèµ„ (å…ƒ)"},
            color="experience_req",
        )
        fig_exp_box.update_layout(showlegend=False)
        st.plotly_chart(fig_exp_box, use_container_width=True)

        # è–ªèµ„ç»Ÿè®¡è¡¨æ ¼
        st.markdown("#### ğŸ“Š è–ªèµ„ç»Ÿè®¡æ‘˜è¦")
        salary_stats = (
            salary_df.groupby("education_req")["salary_avg"]
            .agg(["count", "mean", "median", "min", "max"])
            .round(0)
        )
        salary_stats.columns = ["èŒä½æ•°", "å¹³å‡å€¼", "ä¸­ä½æ•°", "æœ€å°å€¼", "æœ€å¤§å€¼"]
        st.dataframe(salary_stats, use_container_width=True)
    else:
        st.warning("ç­›é€‰åæ— æœ‰æ•ˆè–ªèµ„æ•°æ®")

# ============================================================
# Tab 4: å‘å¸ƒæ—¶é—´è¶‹åŠ¿
# ============================================================
with tab4:
    st.subheader("ğŸ“… å‘å¸ƒæ—¶é—´è¶‹åŠ¿")

    # æ—¶é—´ç²’åº¦é€‰æ‹©
    time_granularity = st.radio("é€‰æ‹©æ—¶é—´ç²’åº¦", ["æŒ‰å¤©", "æŒ‰å‘¨"], horizontal=True)

    time_df = filtered_df.dropna(subset=["publish_date"]).copy()

    if len(time_df) > 0:
        if time_granularity == "æŒ‰å¤©":
            time_df["date"] = time_df["publish_date"].dt.date
            time_counts = time_df.groupby("date").size().reset_index(name="count")
            time_counts["date"] = pd.to_datetime(time_counts["date"])
        else:
            time_df["week"] = (
                time_df["publish_date"].dt.to_period("W").apply(lambda x: x.start_time)
            )
            time_counts = time_df.groupby("week").size().reset_index(name="count")
            time_counts.columns = ["date", "count"]

        fig_line = px.line(
            time_counts,
            x="date",
            y="count",
            title=f"èŒä½å‘å¸ƒè¶‹åŠ¿ï¼ˆ{time_granularity}ï¼‰",
            labels={"date": "æ—¥æœŸ", "count": "èŒä½æ•°é‡"},
            markers=True,
        )
        fig_line.update_layout(
            xaxis_title="æ—¥æœŸ", yaxis_title="èŒä½æ•°é‡", hovermode="x unified"
        )
        st.plotly_chart(fig_line, use_container_width=True)

        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ®"):
            st.dataframe(time_counts, use_container_width=True)
    else:
        st.warning("ç­›é€‰åæ— æœ‰æ•ˆæ—¶é—´æ•°æ®")

# ============================================================
# Tab 5: å…³é”®è¯è¯äº‘
# ============================================================
with tab5:
    st.subheader("â˜ï¸ å…³é”®è¯è¯äº‘")

    # åˆå¹¶æ‰€æœ‰å…³é”®è¯
    all_desc_keywords = []
    all_req_keywords = []

    for keywords in filtered_df["description_keywords"]:
        if isinstance(keywords, list):
            all_desc_keywords.extend(keywords)

    for keywords in filtered_df["requirement_keywords"]:
        if isinstance(keywords, list):
            all_req_keywords.extend(keywords)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### èŒä½æè¿°å…³é”®è¯")
        if all_desc_keywords:
            desc_freq = Counter(all_desc_keywords)

            # ç”Ÿæˆè¯äº‘
            # ä¸­æ–‡å­—ä½“è®¾ç½®è¯´æ˜ï¼š
            # 1. å¦‚æœç³»ç»Ÿå®‰è£…äº†ä¸­æ–‡å­—ä½“ï¼Œå¯ä»¥æŒ‡å®šå­—ä½“è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
            #    font_path = "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"  # Linux
            #    font_path = "C:/Windows/Fonts/msyh.ttc"  # Windows (å¾®è½¯é›…é»‘)
            #    font_path = "/System/Library/Fonts/PingFang.ttc"  # macOS
            # 2. å¦‚æœä¸æŒ‡å®šå­—ä½“ï¼Œä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹å—
            # 3. æ¨èåœ¨éƒ¨ç½²æ—¶ç¡®ä¿ç³»ç»Ÿæœ‰ä¸­æ–‡å­—ä½“æ”¯æŒ

            try:
                # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“ï¼ˆæ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©ï¼‰
                import platform

                system = platform.system()
                if system == "Windows":
                    font_path = "C:/Windows/Fonts/msyh.ttc"
                elif system == "Darwin":  # macOS
                    font_path = "/System/Library/Fonts/PingFang.ttc"
                else:  # Linux
                    font_path = "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"

                wc_desc = WordCloud(
                    width=800,
                    height=400,
                    background_color="white",
                    font_path=font_path,
                    max_words=100,
                    colormap="viridis",
                ).generate_from_frequencies(desc_freq)
            except Exception:
                # å¦‚æœå­—ä½“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
                wc_desc = WordCloud(
                    width=800,
                    height=400,
                    background_color="white",
                    max_words=100,
                    colormap="viridis",
                ).generate_from_frequencies(desc_freq)

            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wc_desc, interpolation="bilinear")
            ax.axis("off")
            st.pyplot(fig)

            # æ˜¾ç¤ºè¯é¢‘ç»Ÿè®¡
            with st.expander("æŸ¥çœ‹å…³é”®è¯è¯é¢‘ (Top 20)"):
                top_desc = pd.DataFrame(
                    desc_freq.most_common(20), columns=["å…³é”®è¯", "é¢‘æ¬¡"]
                )
                st.dataframe(top_desc, use_container_width=True)
        else:
            st.info("æš‚æ— èŒä½æè¿°å…³é”®è¯æ•°æ®")

    with col2:
        st.markdown("#### èŒä½è¦æ±‚å…³é”®è¯")
        if all_req_keywords:
            req_freq = Counter(all_req_keywords)

            try:
                import platform

                system = platform.system()
                if system == "Windows":
                    font_path = "C:/Windows/Fonts/msyh.ttc"
                elif system == "Darwin":
                    font_path = "/System/Library/Fonts/PingFang.ttc"
                else:
                    font_path = "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"

                wc_req = WordCloud(
                    width=800,
                    height=400,
                    background_color="white",
                    font_path=font_path,
                    max_words=100,
                    colormap="plasma",
                ).generate_from_frequencies(req_freq)
            except Exception:
                wc_req = WordCloud(
                    width=800,
                    height=400,
                    background_color="white",
                    max_words=100,
                    colormap="plasma",
                ).generate_from_frequencies(req_freq)

            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wc_req, interpolation="bilinear")
            ax.axis("off")
            st.pyplot(fig)

            with st.expander("æŸ¥çœ‹å…³é”®è¯è¯é¢‘ (Top 20)"):
                top_req = pd.DataFrame(
                    req_freq.most_common(20), columns=["å…³é”®è¯", "é¢‘æ¬¡"]
                )
                st.dataframe(top_req, use_container_width=True)
        else:
            st.info("æš‚æ— èŒä½è¦æ±‚å…³é”®è¯æ•°æ®")

# ============================================================
# Tab 6: åŸå§‹æ•°æ®
# ============================================================
with tab6:
    st.subheader("ğŸ“‹ åŸå§‹æ•°æ®æŸ¥çœ‹")

    st.write(f"å…± {len(filtered_df)} æ¡è®°å½•")

    # æ˜¾ç¤ºæ•°æ®ï¼ˆéšè—å¤æ‚çš„åˆ—è¡¨å­—æ®µï¼‰
    display_cols = [
        "job_id",
        "company_name",
        "title",
        "source_platform",
        "work_type",
        "category",
        "education_req",
        "experience_req",
        "salary_min",
        "salary_max",
        "publish_date",
    ]

    st.dataframe(
        filtered_df[display_cols].head(100), use_container_width=True, height=600
    )

    st.caption("* ä»…æ˜¾ç¤ºå‰ 100 æ¡è®°å½•")

# ============================================================
# é¡µè„š
# ============================================================
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        ğŸ“Š èŒä½æ•°æ®åˆ†æä»ªè¡¨æ¿ | åŸºäº Streamlit + Plotly æ„å»º
    </div>
    """,
    unsafe_allow_html=True,
)
